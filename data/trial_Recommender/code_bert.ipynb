{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-03T19:32:11.237759Z",
     "iopub.status.busy": "2023-07-03T19:32:11.237366Z",
     "iopub.status.idle": "2023-07-03T19:32:17.007852Z",
     "shell.execute_reply": "2023-07-03T19:32:17.006478Z",
     "shell.execute_reply.started": "2023-07-03T19:32:11.237730Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (2.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from datasets) (1.24.2)\n",
      "Requirement already satisfied: xxhash in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: aiohttp in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: multiprocess in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from datasets) (0.16.4)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: pandas in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: packaging in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from datasets) (23.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
      "Requirement already satisfied: filelock in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.9.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: transformers in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (4.30.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from transformers) (2023.3.23)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from transformers) (1.24.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: filelock in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: requests in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: fsspec in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from requests->transformers) (2022.12.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (0.20.3)\n",
      "Requirement already satisfied: pyyaml in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from accelerate) (1.24.2)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from accelerate) (2.0.0)\n",
      "Requirement already satisfied: psutil in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from accelerate) (5.9.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from accelerate) (23.0)\n",
      "Requirement already satisfied: filelock in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (4.5.0)\n",
      "Requirement already satisfied: sympy in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages (from sympy->torch>=1.6.0->accelerate) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-03T19:06:40.241158Z",
     "iopub.status.busy": "2023-07-03T19:06:40.239928Z",
     "iopub.status.idle": "2023-07-03T19:06:46.255394Z",
     "shell.execute_reply": "2023-07-03T19:06:46.254435Z",
     "shell.execute_reply.started": "2023-07-03T19:06:40.241120Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset, load_metric # Load data\n",
    "from transformers import AutoTokenizer # Tokenisation\n",
    "from transformers import AutoModelForSequenceClassification # Classification\n",
    "from transformers import TrainingArguments \n",
    "from transformers import Trainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-03T19:08:23.815355Z",
     "iopub.status.busy": "2023-07-03T19:08:23.814854Z",
     "iopub.status.idle": "2023-07-03T19:08:23.827493Z",
     "shell.execute_reply": "2023-07-03T19:08:23.826300Z",
     "shell.execute_reply.started": "2023-07-03T19:08:23.815315Z"
    }
   },
   "outputs": [],
   "source": [
    "# The input data dir. Should contain the .tsv files (or other data files) for the task.\n",
    "DATA_DIR = \"/Users/ankit/Downloads/Ideathon/trial_Recommender/ideathon/data/\"\n",
    "\n",
    "LLM_MODEL = 'bert-base-uncased'\n",
    "#LLM_MODEL = \"vinai/bertweet-base\"\n",
    "\n",
    "# The name of the task to train.I'm going to name this 'yelp'.\n",
    "TASK_NAME = 'complaints'\n",
    "\n",
    "# The output directory where the fine-tuned model and checkpoints will be written.\n",
    "OUTPUT_DIR = f'/Users/ankit/Downloads/Ideathon/trial_Recommender/ideathon/outputs/{TASK_NAME}/'\n",
    "\n",
    "# The directory where the evaluation reports will be written to.\n",
    "REPORTS_DIR = f'/Users/ankit/Downloads/Ideathon/trial_Recommender/ideathon/reports/{TASK_NAME}_evaluation_report/'\n",
    "\n",
    "# This is where BERT will look for pre-trained models to load parameters from.\n",
    "CACHE_DIR = '/Users/ankit/Downloads/Ideathon/trial_Recommender/ideathon/cache/'\n",
    "\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR)\n",
    "if not os.path.exists(CACHE_DIR):\n",
    "    os.makedirs(CACHE_DIR)\n",
    "if os.path.exists(REPORTS_DIR) and os.listdir(REPORTS_DIR):\n",
    "        REPORTS_DIR += f'/report_{len(os.listdir(REPORTS_DIR))}'\n",
    "        os.makedirs(REPORTS_DIR)\n",
    "if not os.path.exists(REPORTS_DIR):\n",
    "    os.makedirs(REPORTS_DIR)\n",
    "    REPORTS_DIR += f'/report_{len(os.listdir(REPORTS_DIR))}'\n",
    "    os.makedirs(REPORTS_DIR)\n",
    "#if os.path.exists(OUTPUT_DIR) and os.listdir(OUTPUT_DIR):\n",
    "#        raise ValueError(\"Output directory ({}) already exists and is not empty.\".format(OUTPUT_DIR))\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the raw data and load into dataset objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-03T19:30:50.135350Z",
     "iopub.status.busy": "2023-07-03T19:30:50.134955Z",
     "iopub.status.idle": "2023-07-03T19:30:50.330088Z",
     "shell.execute_reply": "2023-07-03T19:30:50.329328Z",
     "shell.execute_reply.started": "2023-07-03T19:30:50.135308Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Data--\n",
      "                                         concatenated  numeric_condition\n",
      "0  Study on Examination of Therapeutic Efficacy a...                  2\n",
      "1  Factors Influencing Social Functioning of Peop...                  2\n",
      "2  A Study to Assess the Rate of Hospitalization ...                  2\n",
      "3  Involuntary Memories Investigation in Schizoph...                  2\n",
      "4  Perception of Facial Emotions in Schizophrenia...                  2\n",
      "Data Length-- 1028\n",
      "Sample Data after transformation--\n",
      "    label                                               text\n",
      "0      2  Study on Examination of Therapeutic Efficacy a...\n",
      "1      2  Factors Influencing Social Functioning of Peop...\n",
      "2      2  A Study to Assess the Rate of Hospitalization ...\n",
      "3      2  Involuntary Memories Investigation in Schizoph...\n",
      "4      2  Perception of Facial Emotions in Schizophrenia...\n",
      "Data Length after transformation-- 1028\n",
      "Train, Dev and Test sizes-- 657 165 206\n"
     ]
    }
   ],
   "source": [
    "raw_df = pd.read_csv('selected_columns.csv', header=None, names=['concatenated', 'numeric_condition'])\n",
    "# binary label - 1 is a complain and 0 is not\n",
    "print(\"Sample Data--\\n\", raw_df.head())\n",
    "print(\"Data Length--\",len(raw_df))\n",
    "\n",
    "bert_df = pd.DataFrame({\n",
    "    #'id':range(len(raw_df)),\n",
    "    'label': raw_df[\"numeric_condition\"],\n",
    "    #'alpha': ['x']*len(raw_df),\n",
    "    'text': raw_df[\"concatenated\"]\n",
    "})\n",
    "print(\"Sample Data after transformation--\\n\", bert_df.head())\n",
    "print(\"Data Length after transformation--\",len(bert_df))\n",
    "\n",
    "# Split the dataset\n",
    "temp_bert_df, test_bert_df = train_test_split(bert_df, test_size=0.2, random_state=42)\n",
    "train_bert_df, dev_bert_df = train_test_split(temp_bert_df, test_size=0.2, random_state=42)\n",
    "print(\"Train, Dev and Test sizes--\", len(train_bert_df), len(dev_bert_df), len(test_bert_df))\n",
    "\n",
    "# Convert to tsv\n",
    "train_bert_df.to_csv('/Users/ankit/Downloads/Ideathon/trial_Recommender/ideathon/data/train.tsv', sep='\\t', index=False, header=True)\n",
    "dev_bert_df.to_csv('/Users/ankit/Downloads/Ideathon/trial_Recommender/ideathon/data/dev.tsv', sep='\\t', index=False, header=True)\n",
    "test_bert_df.to_csv('/Users/ankit/Downloads/Ideathon/trial_Recommender/ideathon/data/test.tsv', sep='\\t', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-03T19:36:26.706784Z",
     "iopub.status.busy": "2023-07-03T19:36:26.706408Z",
     "iopub.status.idle": "2023-07-03T19:36:26.908981Z",
     "shell.execute_reply": "2023-07-03T19:36:26.907949Z",
     "shell.execute_reply.started": "2023-07-03T19:36:26.706758Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /Users/ankit/.cache/huggingface/datasets/csv/default-39117c2677f64854/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 3/3 [00:00<00:00, 4600.70it/s]\n",
      "Extracting data files: 100%|██████████| 3/3 [00:00<00:00, 236.95it/s]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /Users/ankit/.cache/huggingface/datasets/csv/default-39117c2677f64854/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 34.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 657\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 165\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 206\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_files = {\n",
    "    \"train\": \"/Users/ankit/Downloads/Ideathon/trial_Recommender/ideathon/data/train.tsv\",\n",
    "    \"val\": \"/Users/ankit/Downloads/Ideathon/trial_Recommender/ideathon/data/dev.tsv\",\n",
    "    \"test\": \"/Users/ankit/Downloads/Ideathon/trial_Recommender/ideathon/data/test.tsv\"\n",
    "}\n",
    "\n",
    "twt_datasets = load_dataset(\"csv\", data_files=data_files, delimiter='\\t')\n",
    "print(twt_datasets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-03T19:36:35.537511Z",
     "iopub.status.busy": "2023-07-03T19:36:35.537126Z",
     "iopub.status.idle": "2023-07-03T19:36:46.327271Z",
     "shell.execute_reply": "2023-07-03T19:36:46.326085Z",
     "shell.execute_reply.started": "2023-07-03T19:36:35.537473Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 2.65kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 570/570 [00:00<00:00, 164kB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:01<00:00, 133kB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 6.47kB/s]\n",
      "                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sizes-- Train 657 Eval 165 Test 206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL, \n",
    "                                          use_fast=False,\n",
    "                                          force_download=True)\n",
    "\n",
    "# Function\n",
    "def data_tokenizer(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_data = twt_datasets.map(data_tokenizer, batched=True)\n",
    "train_dataset = tokenized_data[\"train\"]\n",
    "eval_dataset = tokenized_data[\"val\"]\n",
    "test_dataset = tokenized_data[\"test\"]\n",
    "print(\"Data sizes-- Train\",len(train_dataset),\"Eval\",len(eval_dataset), \"Test\",len(test_dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-03T19:08:45.589807Z",
     "iopub.status.busy": "2023-07-03T19:08:45.589453Z",
     "iopub.status.idle": "2023-07-03T19:09:14.126130Z",
     "shell.execute_reply": "2023-07-03T19:09:14.125273Z",
     "shell.execute_reply.started": "2023-07-03T19:08:45.589780Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(LLM_MODEL, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-03T19:37:09.626263Z",
     "iopub.status.busy": "2023-07-03T19:37:09.625766Z",
     "iopub.status.idle": "2023-07-03T19:37:09.818004Z",
     "shell.execute_reply": "2023-07-03T19:37:09.816792Z",
     "shell.execute_reply.started": "2023-07-03T19:37:09.626223Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6z/7q_3gqys7zgdk6n_tfx83xgw0000gn/T/ipykernel_8084/754301748.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"accuracy\")\n"
     ]
    }
   ],
   "source": [
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-03T19:09:23.570896Z",
     "iopub.status.busy": "2023-07-03T19:09:23.569801Z",
     "iopub.status.idle": "2023-07-03T19:12:56.949747Z",
     "shell.execute_reply": "2023-07-03T19:12:56.948983Z",
     "shell.execute_reply.started": "2023-07-03T19:09:23.570859Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ankit/opt/anaconda3/envs/ankit_env/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "                                                   \n",
      " 40%|████      | 100/249 [55:28<1:32:25, 37.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0024560855235904455, 'eval_accuracy': 1.0, 'eval_runtime': 95.6753, 'eval_samples_per_second': 1.725, 'eval_steps_per_second': 0.219, 'epoch': 1.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 200/249 [1:50:53<31:21, 38.40s/it]  \n",
      " 80%|████████  | 200/249 [1:52:30<31:21, 38.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0009559995960444212, 'eval_accuracy': 1.0, 'eval_runtime': 96.7698, 'eval_samples_per_second': 1.705, 'eval_steps_per_second': 0.217, 'epoch': 2.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 249/249 [2:19:43<00:00, 33.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 8383.3777, 'train_samples_per_second': 0.235, 'train_steps_per_second': 0.03, 'train_loss': 0.09791247815970915, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=249, training_loss=0.09791247815970915, metrics={'train_runtime': 8383.3777, 'train_samples_per_second': 0.235, 'train_steps_per_second': 0.03, 'train_loss': 0.09791247815970915, 'epoch': 3.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\"test_trainer\", \n",
    "                                  evaluation_strategy=\"steps\",\n",
    "                                  eval_steps=100,  \n",
    "                                  save_total_limit=2, \n",
    "                                  metric_for_best_model='accuracy',   \n",
    "                                  greater_is_better=True, \n",
    "                                  load_best_model_at_end=True,\n",
    "                                  report_to=\"none\")\n",
    "trainer = Trainer(model=model, \n",
    "                  args=training_args, \n",
    "                  train_dataset=train_dataset, \n",
    "                  eval_dataset=eval_dataset,\n",
    "                  compute_metrics=compute_metrics\n",
    "                 )\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-03T19:17:01.074607Z",
     "iopub.status.busy": "2023-07-03T19:17:01.074148Z",
     "iopub.status.idle": "2023-07-03T19:17:05.500438Z",
     "shell.execute_reply": "2023-07-03T19:17:05.499433Z",
     "shell.execute_reply.started": "2023-07-03T19:17:01.074579Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [01:38<00:00,  4.71s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.000675668939948082,\n",
       " 'eval_accuracy': 1.0,\n",
       " 'eval_runtime': 106.7889,\n",
       " 'eval_samples_per_second': 1.545,\n",
       " 'eval_steps_per_second': 0.197,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:54<00:00,  4.40s/it]\n"
     ]
    }
   ],
   "source": [
    "results = trainer.predict(test_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"/Users/ankit/Downloads/Ideathon/trial_Recommender\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_path = \"/Users/ankit/Downloads/Ideathon/trial_Recommender\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\", use_fast=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "input_text = \"I'm having Autistic issues for years now\"\n",
    "tokenized_text = tokenizer(input_text,\n",
    "                           truncation=True,\n",
    "                           is_split_into_words=False,\n",
    "                           return_tensors='pt')\n",
    "\n",
    "outputs = model(**tokenized_text)\n",
    "predicted_label = outputs.logits.argmax(-1)\n",
    "\n",
    "print(predicted_label.item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
